{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Faster R-CNN - OPTİMİZE MOD (2 Epoch)\n",
                "\n",
                "Bu notebook, 300 resim ve 2 epoch ile eğitilecek şekilde yapılandırılmıştır.\n",
                "\n",
                "**Ayarlar:**\n",
                "- **Veri Sayısı:** 300 Resim\n",
                "- **Resim Boyutu:** 600x600 (Hız İçin)\n",
                "- **Epoch:** 2\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import torch\n",
                "import torchvision\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "from PIL import Image\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
                "import matplotlib.pyplot as plt\n",
                "import matplotlib.patches as patches\n",
                "from torchvision.transforms import functional as F\n",
                "\n",
                "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
                "print(f'Kullanılan cihaz: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Veri Hazırlığı"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- AYARLAR ---\n",
                "root_dir = r\"C:\\Users\\gozde\\OneDrive\\Masaüstü\"\n",
                "images_dir = os.path.join(root_dir, \"images\")\n",
                "csv_path = os.path.join(root_dir, \"train.csv\")\n",
                "TARGET_SIZE = (600, 600)\n",
                "\n",
                "try:\n",
                "    col_names = ['filename', 'xmin', 'ymin', 'xmax', 'ymax', 'class', 'width', 'height']\n",
                "    df = pd.read_csv(csv_path, header=None, names=col_names)\n",
                "    df['filename'] = df['filename'].astype(str).str.replace('test', 'train')\n",
                "    \n",
                "    # Dosya Kontrolü\n",
                "    df['exists'] = df['filename'].apply(lambda x: os.path.exists(os.path.join(images_dir, x)))\n",
                "    df = df[df['exists']]\n",
                "    \n",
                "    # --- LİMİT: 300 Resim ---\n",
                "    limit = 300\n",
                "    unique_files = df['filename'].unique()\n",
                "    if len(unique_files) > limit:\n",
                "        selected = unique_files[:limit]\n",
                "        df = df[df['filename'].isin(selected)]\n",
                "    \n",
                "    print(f\"Eğitimde Kullanılacak Resim Sayısı: {df['filename'].nunique()}\")\n",
                "\n",
                "except Exception as e:\n",
                "    print(f\"Hata: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Dataset Sınıfı"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ProductDataset(Dataset):\n",
                "    def __init__(self, dataframe, image_dir, target_size=(600, 600)):\n",
                "        self.df = dataframe\n",
                "        self.image_dir = image_dir\n",
                "        self.target_size = target_size\n",
                "        self.image_ids = self.df['filename'].unique()\n",
                "        self.classes = self.df['class'].unique().tolist()\n",
                "        self.class_to_idx = {cls: i+1 for i, cls in enumerate(self.classes)}\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.image_ids)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        image_id = self.image_ids[idx]\n",
                "        records = self.df[self.df['filename'] == image_id]\n",
                "        image_path = os.path.join(self.image_dir, image_id)\n",
                "        \n",
                "        image = Image.open(image_path).convert(\"RGB\")\n",
                "        w_old, h_old = image.size\n",
                "        \n",
                "        image = image.resize(self.target_size, resample=Image.BILINEAR)\n",
                "        w_new, h_new = self.target_size\n",
                "        \n",
                "        x_scale = w_new / w_old\n",
                "        y_scale = h_new / h_old\n",
                "        \n",
                "        boxes = records[['xmin', 'ymin', 'xmax', 'ymax']].values\n",
                "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
                "        \n",
                "        boxes[:, 0] *= x_scale\n",
                "        boxes[:, 1] *= y_scale\n",
                "        boxes[:, 2] *= x_scale\n",
                "        boxes[:, 3] *= y_scale\n",
                "        \n",
                "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
                "        labels = torch.as_tensor([self.class_to_idx[c] for c in records['class']], dtype=torch.int64)\n",
                "        \n",
                "        target = {}\n",
                "        target[\"boxes\"] = boxes\n",
                "        target[\"labels\"] = labels\n",
                "        target[\"image_id\"] = torch.tensor([idx])\n",
                "        target[\"area\"] = area\n",
                "        target[\"iscrowd\"] = torch.zeros((len(boxes),), dtype=torch.int64)\n",
                "\n",
                "        return F.to_tensor(image), target\n",
                "\n",
                "def collate_fn(batch):\n",
                "    return tuple(zip(*batch))\n",
                "\n",
                "if 'df' in locals() and len(df) > 0:\n",
                "    dataset = ProductDataset(df, images_dir, target_size=TARGET_SIZE)\n",
                "    data_loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
                "    print(\"Dataset Hazır.\")\n",
                "else:\n",
                "    print(\"Veri yok.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Eğitim (2 Epoch)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_model(num_classes):\n",
                "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
                "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
                "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
                "    return model\n",
                "\n",
                "if 'dataset' in locals() and len(dataset) > 0:\n",
                "    num_classes = len(dataset.classes) + 1 \n",
                "    model = get_model(num_classes)\n",
                "    model.to(device)\n",
                "    \n",
                "    params = [p for p in model.parameters() if p.requires_grad]\n",
                "    optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
                "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
                "\n",
                "    # --- GÜNCELLEME: 2 Epoch ---\n",
                "    num_epochs = 2\n",
                "    loss_history = []\n",
                "\n",
                "    print(\"Eğitim Başladı...\")\n",
                "    try:\n",
                "        for epoch in range(num_epochs):\n",
                "            model.train()\n",
                "            epoch_loss = 0\n",
                "            count = 0\n",
                "            for images, targets in data_loader:\n",
                "                images = list(image.to(device) for image in images)\n",
                "                targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
                "                \n",
                "                loss_dict = model(images, targets)\n",
                "                losses = sum(loss for loss in loss_dict.values())\n",
                "                \n",
                "                optimizer.zero_grad()\n",
                "                losses.backward()\n",
                "                optimizer.step()\n",
                "                \n",
                "                val_loss = losses.item()\n",
                "                loss_history.append(val_loss)\n",
                "                epoch_loss += val_loss\n",
                "                \n",
                "                count += 1\n",
                "                if count % 20 == 0:\n",
                "                    print(f\"Epoch: {epoch+1} | Adım: {count} | Loss: {val_loss:.4f}\")\n",
                "            \n",
                "            print(f\"--- Epoch {epoch+1} Tamamlandı. Ort. Loss: {epoch_loss/len(data_loader):.4f} ---\")\n",
                "            lr_scheduler.step()\n",
                "            \n",
                "        torch.save(model.state_dict(), os.path.join(root_dir, 'faster_rcnn_model.pth'))\n",
                "        print(\"Eğitim Bitti, Model Kaydedildi!\")\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Hata: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Sonuç Görselleştirme"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def visualize_results(model, dataset, loss_history, device):\n",
                "    model.eval()\n",
                "    if len(dataset) == 0: return\n",
                "    \n",
                "    idx = np.random.randint(0, len(dataset))\n",
                "    img, target = dataset[idx]\n",
                "    \n",
                "    with torch.no_grad():\n",
                "        prediction = model([img.to(device)])[0]\n",
                "    \n",
                "    img_display = img.permute(1, 2, 0).cpu().numpy()\n",
                "    \n",
                "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
                "    \n",
                "    if loss_history:\n",
                "        ax1.plot(loss_history, label='Loss', color='tab:blue')\n",
                "        ax1.set_title(f'Loss Grafiği')\n",
                "    \n",
                "    ax2.imshow(img_display)\n",
                "    ax2.set_title(f'Test Sonucu')\n",
                "    ax2.axis('off')\n",
                "    \n",
                "    boxes = prediction['boxes'].cpu().numpy()\n",
                "    scores = prediction['scores'].cpu().numpy()\n",
                "    \n",
                "    score_threshold = 0.3\n",
                "    for i, box in enumerate(boxes):\n",
                "        if scores[i] > score_threshold:\n",
                "            xmin, ymin, xmax, ymax = box\n",
                "            rect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, linewidth=2, edgecolor='#00FF00', facecolor='none')\n",
                "            ax2.add_patch(rect)\n",
                "            \n",
                "    plt.tight_layout()\n",
                "    plt.show()\n",
                "\n",
                "if 'loss_history' in locals() and len(loss_history) > 0:\n",
                "    visualize_results(model, dataset, loss_history, device)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}